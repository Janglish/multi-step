{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "089d1425-e4b4-4c77-82c6-82a419daef3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "0.00 % has done.\n",
      "1.00 % has done.\n",
      "2.00 % has done.\n",
      "3.00 % has done.\n",
      "4.00 % has done.\n",
      "5.00 % has done.\n",
      "tensor(0.0478, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0287, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.1332, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0243, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0121, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0188, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0030, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0301, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0069, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0037, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0049, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0163, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0013, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0024, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0025, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0178, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0024, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0158, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0189, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0015, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0333, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0328, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0011, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0168, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0008, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0150, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0167, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0150, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0026, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0029, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0024, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0405, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0156, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0154, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0011, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0292, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0272, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0017, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0016, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0011, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0164, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0149, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0012, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0012, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0169, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0166, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0146, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0168, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0014, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0013, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0014, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0014, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0166, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0013, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0011, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0138, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0163, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0477, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0164, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0011, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0018, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0322, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0469, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0149, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0154, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0017, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0028, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0024, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0020, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0017, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0140, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0169, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0156, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0163, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0011, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0180, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0155, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0165, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0008, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0152, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0171, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0142, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0008, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0157, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0164, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0151, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0139, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0148, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0012, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0019, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0017, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0015, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0159, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0020, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0142, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0172, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0014, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0164, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0012, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0158, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0143, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0142, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0008, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0011, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0143, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0008, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0012, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0143, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0159, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0161, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0160, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0153, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0153, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0175, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0145, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0160, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0014, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0017, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0160, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0011, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0302, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0299, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0159, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0012, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0175, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0163, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0156, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0148, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0148, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0168, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0148, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0285, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0011, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0008, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0137, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0012, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0641, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0291, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0286, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0008, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0275, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0141, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0144, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.1091, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0444, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0034, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0174, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0012, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0152, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0147, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0136, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0014, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0029, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0019, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0011, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0134, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0012, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0336, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0326, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0167, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0147, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0172, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0296, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0177, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0018, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0149, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0027, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0179, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0144, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0161, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0026, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0018, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0162, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0140, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0144, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0152, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0310, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0012, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0173, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0165, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0002, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0155, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0146, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0161, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0161, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0155, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0174, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0156, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0312, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.1099, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0018, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0141, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0158, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0171, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0168, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0311, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0148, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0291, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0149, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0008, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0161, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0308, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0160, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0148, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0149, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0011, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0436, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0164, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0155, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0159, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0008, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0163, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0002, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0147, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0311, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0148, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0307, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0157, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0149, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0175, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0325, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0159, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0011, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0015, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0431, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0165, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0008, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0012, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0278, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0163, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0150, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0157, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0158, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0316, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0150, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0456, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0145, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0283, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0162, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0143, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0015, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0434, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0153, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0154, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0019, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0022, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0021, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0157, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0304, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0008, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0149, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0322, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0311, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0154, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0150, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0149, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0162, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0155, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0327, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0158, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0002, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0154, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0150, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0151, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0161, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0157, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0150, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0166, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0002, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0321, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0302, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0302, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0165, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0006, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0141, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0157, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0142, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0148, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0011, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0150, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0159, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0011, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0136, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0144, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0009, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0010, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0152, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0157, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0155, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0151, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0152, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0148, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0161, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0152, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0002, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0143, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0002, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0158, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0005, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0004, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0151, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0151, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0003, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0152, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0165, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0161, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0149, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0144, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0163, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0292, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0304, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0284, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0008, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0007, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0314, grad_fn=<SmoothL1LossBackward0>)\n",
      "tensor(0.0295, grad_fn=<SmoothL1LossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5536/1755579949.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mREPLAY_START_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mUPDATE_POLICY_FREQ\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 \u001b[0mpolicy_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mUPDATE_TARGET_FREQ\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mtarget_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\University\\研究室\\研究\\実験\\multi-step learning\\breakout\\Agent.py\u001b[0m in \u001b[0;36mupdate_network\u001b[1;34m(self, target_net, optimizer)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mexperiences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTransition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\University\\研究室\\研究\\実験\\multi-step learning\\breakout\\ReplayBuffer.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mexperiences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\University\\研究室\\研究\\実験\\multi-step learning\\breakout\\ReplayBuffer.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[0mexperiences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "import zlib\n",
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from Agent import Agent\n",
    "from Logger import Logger\n",
    "from Observer import Observer\n",
    "from ReplayBuffer import ReplayBuffer\n",
    "from collections import namedtuple, deque\n",
    "from gym.wrappers import AtariPreprocessing, Monitor\n",
    "\n",
    "# 設定\n",
    "BUFFER_SIZE = 1000000\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "INITIAL_EPS = 1.0\n",
    "FINAL_EPS = 0.1\n",
    "DECAY_EPS = 0.01\n",
    "LEARNING_RATE = 0.00025\n",
    "UPDATE_POLICY_FREQ = 4\n",
    "UPDATE_TARGET_FREQ = 10000\n",
    "REPLAY_START_SIZE = 50000\n",
    "TOTAL_STEPS = 1000000\n",
    "EVALUATION_FREQ = 10000\n",
    "TOTAL_EVALUATION_STEPS = 5000\n",
    "MAX_EVALUATION_STEPS = 108000\n",
    "N_STEP = 3\n",
    "\n",
    "seed = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "Transition = namedtuple(\"Transition\", (\"state\", \"action\", \"next_state\", \"reward\", \"expo\"))\n",
    "\n",
    "# 環境構築\n",
    "ENV = \"BreakoutNoFrameskip-v4\"\n",
    "env = gym.make(ENV)\n",
    "env.seed(seed)\n",
    "env = AtariPreprocessing(env, noop_max=30, frame_skip=4, screen_size=84, grayscale_obs=True)\n",
    "n_actions = env.action_space.n\n",
    "env = Observer(env=env, device=device, seed=seed)\n",
    "\n",
    "# リプレイバッファ\n",
    "replay_buffer = ReplayBuffer(capacity=BUFFER_SIZE, n_step=N_STEP, gamma=GAMMA, \n",
    "                             Transition=Transition, device=device)\n",
    "logger = Logger(seed=seed)\n",
    "\n",
    "# ネットワーク構築\n",
    "h, w = 84, 84\n",
    "\n",
    "policy_net = Agent(h=h, w=w, n_actions=n_actions, gamma=GAMMA, initial_eps=INITIAL_EPS, final_eps=FINAL_EPS, \n",
    "                   decay_eps=DECAY_EPS, replay_buffer=replay_buffer, seed=seed, batch_size=BATCH_SIZE, \n",
    "                   device=device).to(device)\n",
    "target_net = Agent(h=h, w=w, n_actions=n_actions, gamma=GAMMA, initial_eps=INITIAL_EPS, final_eps=FINAL_EPS, \n",
    "                   decay_eps=DECAY_EPS, replay_buffer=replay_buffer, seed=seed, batch_size=BATCH_SIZE, \n",
    "                   device=device).to(device)\n",
    "\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "policy_net.train()\n",
    "target_net.eval()\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE, eps=0.01/BATCH_SIZE)\n",
    "\n",
    "# 訓練開始\n",
    "print(device)\n",
    "\n",
    "env.reset()        \n",
    "steps_done = 0\n",
    "start = time.time()\n",
    "cnt = 0\n",
    "\n",
    "while steps_done < TOTAL_STEPS:\n",
    "            \n",
    "    lives = 5\n",
    "    done = False\n",
    "    frames = deque([env.reset()] * 4, maxlen=4)\n",
    "    state = torch.cat([frame for frame in frames], axis=1).to(device)\n",
    "            \n",
    "    while not done:\n",
    "        \n",
    "        action = policy_net.policy(state, True)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        frames.append(next_state)\n",
    "        next_state = torch.cat([frame for frame in frames], axis=1).to(device)\n",
    "        \n",
    "        if lives != info[\"lives\"]:\n",
    "            lives = info[\"lives\"]\n",
    "            replay_buffer.push((state, action, None, reward, torch.tensor(N_STEP)))\n",
    "        else:\n",
    "            replay_buffer.push((state, action, next_state, reward, torch.tensor(N_STEP)))\n",
    "\n",
    "        state = next_state\n",
    "        \n",
    "        # ネットワーク更新\n",
    "        if len(replay_buffer.buffer) > REPLAY_START_SIZE:\n",
    "            if steps_done % UPDATE_POLICY_FREQ == 0:\n",
    "                policy_net.update_network(target_net, optimizer)\n",
    "            if steps_done % UPDATE_TARGET_FREQ == 0:\n",
    "                target_net.load_state_dict(policy_net.state_dict())\n",
    "                \n",
    "        # 評価\n",
    "        if steps_done % EVALUATION_FREQ == 0:\n",
    "            policy_net.eval()\n",
    "            eval_rewards = []\n",
    "            eval_steps_done = 0 \n",
    "            eval_env = gym.make(ENV)\n",
    "            eval_env = AtariPreprocessing(eval_env, noop_max=30, frame_skip=4, screen_size=84, grayscale_obs=True)\n",
    "            eval_env = Observer(eval_env, device=device, seed=seed+steps_done//EVALUATION_FREQ)\n",
    "            while eval_steps_done < TOTAL_EVALUATION_STEPS:\n",
    "                eval_done = False\n",
    "                eval_episode_reward = 0\n",
    "                eval_episode_steps_done = 0\n",
    "                eval_frames = deque([eval_env.reset()] * 4, maxlen=4)\n",
    "                eval_state = torch.cat([eval_frame for eval_frame in eval_frames], axis=1).to(device)\n",
    "                while (not eval_done) and (eval_episode_steps_done < MAX_EVALUATION_STEPS):\n",
    "                    eval_action = policy_net.policy(eval_state, False)\n",
    "                    eval_next_state, eval_reward, eval_done, eval_info = eval_env.step(eval_action)\n",
    "                    eval_frames.append(eval_next_state)\n",
    "                    eval_next_state = torch.cat([eval_frame for eval_frame in eval_frames], axis=1).to(device)\n",
    "                    eval_steps_done += 1\n",
    "                    eval_episode_steps_done += 1\n",
    "                    eval_episode_reward += eval_reward.item()\n",
    "                    eval_rewards.append(eval_episode_reward)\n",
    "            logger.write(sum(eval_rewards) / len(eval_rewards))\n",
    "            eval_env.close()\n",
    "            policy_net.train()\n",
    "            print(\"{:.2f} % has done.\".format(steps_done / TOTAL_STEPS * 100))\n",
    "            \n",
    "        steps_done += 1\n",
    "\n",
    "logger.save(policy_net, path_or_buf=\"logs/breakout.pkl\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c21fcf-ebee-4a68-aac1-f2a67b2c3438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video has recorded\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import torch\n",
    "from Logger import Logger\n",
    "from Observer import Observer\n",
    "from collections import namedtuple, deque\n",
    "from gym.wrappers import AtariPreprocessing, Monitor\n",
    "\n",
    "ENV = \"BreakoutNoFrameskip-v4\"\n",
    "seed = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Transition = namedtuple(\"Transition\", (\"state\", \"action\", \"next_state\", \"reward\"))\n",
    "\n",
    "# ビデオ録画\n",
    "env = gym.make(ENV)\n",
    "env = AtariPreprocessing(env, noop_max=0, frame_skip=4, screen_size=84, grayscale_obs=True)\n",
    "env = Monitor(env, \"Video\", force=True)\n",
    "env = Observer(env=env, device=device, seed=seed)\n",
    "\n",
    "logger = Logger()\n",
    "model = logger.load(path_or_buf=\"logs/breakout.pkl\")\n",
    "#print(model)\n",
    "\n",
    "done = False\n",
    "state = env.reset()\n",
    "frames = deque([state] * 4, maxlen=4)\n",
    "state = torch.cat([frame for frame in frames], axis=1).to(device)\n",
    "while not done:\n",
    "    action = model.policy(state)\n",
    "    next_state, reward, done, info = env.step(action)\n",
    "    frames.append(next_state)\n",
    "    next_state = torch.cat([frame for frame in frames], axis=1).to(device)\n",
    "    state = next_state\n",
    "env.close()\n",
    "print(\"Video has recorded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8979b66-70c1-4fc3-90cb-b61c39cb4468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1034afde-0e33-4d60-96b7-10cf15976bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states : (tensor([1.]), tensor([2.]), None, tensor([4.]), tensor([5.]), None, tensor([7.]), tensor([8.]), None)\n",
      "non_final_mask : tensor([ True,  True, False,  True,  True, False,  True,  True, False])\n",
      "non_final_next_states : tensor([1., 2., 4., 5., 7., 8.])\n",
      "state_action_values : tensor([[0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0],\n",
      "        [0]])\n",
      "next_state_values : tensor([[1.],\n",
      "        [2.],\n",
      "        [0.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [0.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [0.]])\n",
      "expected_state_action_values : tensor([[1.9900, 2.9800, 1.0000, 4.9600, 5.9500, 1.0000, 7.9300, 8.9200, 1.0000]])\n",
      "tensor(3.4700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fooma\\AppData\\Local\\Temp/ipykernel_1940/1535036976.py:30: UserWarning: Using a target size (torch.Size([1, 9])) that is different to the input size (torch.Size([9, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "f = lambda x : x\n",
    "\n",
    "states = ()\n",
    "for i in range(9):\n",
    "    if i % 3 == 2:\n",
    "        states += (None,)\n",
    "    else:\n",
    "        states += (torch.tensor(i + 1, dtype=torch.float32).unsqueeze(0),)\n",
    "print(\"states :\", states)\n",
    "\n",
    "non_final_mask = torch.tensor(tuple(map(lambda s : s is not None, states)), dtype=torch.bool)\n",
    "print(\"non_final_mask :\", non_final_mask)\n",
    "\n",
    "non_final_next_states = torch.cat([s for s in states if s is not None])\n",
    "print(\"non_final_next_states :\", non_final_next_states)\n",
    "\n",
    "state_action_values = torch.tensor([0 for i in range(9)])\n",
    "state_action_values = state_action_values.T.unsqueeze(1)\n",
    "print(\"state_action_values :\", state_action_values)\n",
    "next_state_values = torch.zeros(9)\n",
    "next_state_values[non_final_mask] = f(non_final_next_states)\n",
    "next_state_values = next_state_values.T.unsqueeze(1)\n",
    "print(\"next_state_values :\", next_state_values)\n",
    "expected_state_action_values = 0.99 * next_state_values + 1\n",
    "expected_state_action_values = expected_state_action_values.T\n",
    "print(\"expected_state_action_values :\", expected_state_action_values)\n",
    "loss = F.smooth_l1_loss(state_action_values, expected_state_action_values)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f9ea0-20aa-4b36-965b-73625b470a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2e209f-efab-48d2-b9bf-dffe11dbe9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym.wrappers import AtariPreprocessing\n",
    "\n",
    "env = gym.make(\"BreakoutNoFrameskip-v4\")\n",
    "env = AtariPreprocessing(env, noop_max=30, frame_skip=4, screen_size=84, \n",
    "                         terminal_on_life_loss=True, grayscale_obs=True)\n",
    "\n",
    "state = env.reset()\n",
    "print(env.unwrapped.get_action_meanings())\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babea4d3-847f-4362-94c5-c00ed7387563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from Logger import Logger\n",
    "\n",
    "logs = pd.read_csv(\"logs/logs.csv\")\n",
    "x = range(len(logs[\"reward\"]))\n",
    "y = logs[\"reward\"]\n",
    "\n",
    "plt.plot(x, y, label=\"reward\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "logger = Logger(\"logs\", \"logs_2\")\n",
    "\n",
    "for i in range(len(logs) // 5):\n",
    "    R = logs[i * 5 : i * 5 + 5][\"reward\"].sum()\n",
    "    logger.write(R)\n",
    "    \n",
    "logs[\"reward\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c23ea057-28aa-4179-b648-8e5f529197a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3\n",
      "3 3\n",
      "2 3\n",
      "1 3 3\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "dq = deque([i for i in range(4)], maxlen=4)\n",
    "print(len(dq), dq[-1])\n",
    "dq.popleft()\n",
    "print(len(dq), dq[-1])\n",
    "dq.popleft()\n",
    "print(len(dq), dq[-1])\n",
    "dq.popleft()\n",
    "print(len(dq), dq[0], dq[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3579c6bf-69e0-49ea-96cd-d2b2c9c2a123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "ENV = \"BreakoutNoFrameskip-v4\"\n",
    "env = gym.make(ENV)\n",
    "\n",
    "ans = 0\n",
    "done = False\n",
    "state = env.reset()\n",
    "\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action)\n",
    "    ans += reward\n",
    "print(ans)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3499f7d9-2cd7-4516-8335-31bb10c4cbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
